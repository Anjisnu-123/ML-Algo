## Mapping

### Overview of self-organizing maps (SOM) :
Introduction,need for som,when to use som,key concepts,use cases in unsupervised learning

what are neurons in SOM ? : What are the diff b/w neurons in som and neurons in other neural networks?,how neurons work in som: wright vectors,learning process,neighbourhood function,
competetive learning and topology preservation
(Quantization error,topographic error,som distortion measure,topographic product,silhouette score,u-matrix,hit histogram): description,interpretation

Self-organizing MAp (SOM) : kohonen self organizing maps,neural gas algorithm


## Kohonen self organizing maps
Defination,assumptions,mathematical formulation : step 1: initialization,step 2: finding the best machine unit (BMU),step 3:update the weights:neighbourhood function, step 4: repeat the process.
how to use,when to use,pros and cons,use case.examples,intution/visualization,comparison,evaluation metrics,complexity,real world challenges,code implemetation,variants and extension: batch som,
convolutional som,limitations in real world applications

## Neural gas algorithm
Defination,assumptions:dimensionality,metric space,topology,mathematical formulation,how to use: data prep,initialization,training,shopping criteria,when to use,pros and cons,use case,
example: numerical example,adaption of neural gas algorithm using minisom library,variantas and extensions,limitations in real-world applications


# Decoding textual data
Introduction to topic modeling algorithm,need for topic modeling,when to use topic modeling,key concepts in topic modeling,use cases in industry
key concept in topic modeling : (Latent variables,bag of words) : Description,examples
Probabilistic models: 
Documen topic matrix: description,example,Topic word matrix : Description,example

Metrics for topic modeling : (Perplexity,coherence score,ARI,sillhoute score,Topic coverage,Normalized pointwise mutual information) : Description,calculation,interpretation

## Topic modeling algorithms: latent Dirichlet ,non negative matrix factorixation,latent semantic analysis
Latent dirichlet allocation(LDA): Defination,assumptions: bag of words,document topic distributioon,Topic word dist |,mathematical formulation , How to use it : data prp,initialization<,training,output | when to use,pros and cons,usecase: applications,intution/visualization,comparison,evaluation metric,complexity,Real world challenges,varriants and extensions,limitations in real world applications

##  Non negative matrix factorization  : 
Defination,assuptions: non negativity,dimesionality reduction,when to use,how to use,NMF calculation: using code also,intution/visualization,comparison,evaluation metrics,cmplexity,real world challenges,software implementation,variants and extension,limitations in real world application.


## LSA :
defination,assumptions : term document matrix,latent structure,dimensionality reduction,mathematical formulation,how to use,when to use,pros and cons,use cases,intution/visualization,comparison,evaluation metrics,complexity real world challenges,software impleentation,variants and extension,limtations in real world
